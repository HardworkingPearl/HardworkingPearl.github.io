<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Qiuhao Zeng</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  <style>
    :root {
        --bg: #fdfdfd;        /* clean page background */
        --surface: #f7f9fb;   /* section background */
        --muted: #6b7280;     /* muted gray text */
        --text: #1e293b;      /* main text */
        --accent: #3b82f6;    /* primary blue */
        --accent-2: #10b981;  /* secondary green */
        --card: #ffffff;      /* card background */
        --chip: #f1f5f9;      /* chip/tag background */
        --border: #e2e8f0;    /* light border */
    }
    * { box-sizing: border-box; }
    html, body { margin: 0; padding: 0; }
    body {
      font-family: Inter, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif;
      background: linear-gradient(180deg, var(--bg), #93daf4 60%);
      color: var(--text);
      line-height: 1.6;
    }
    a { color: var(--accent); text-decoration: none; }
    a:hover { text-decoration: underline; }

    .container { max-width: 1100px; margin: 0 auto; padding: 24px; }

    header.hero {
      display: grid; grid-template-columns: 160px 1fr; grid-gap: 24px; align-items: center;
      background: radial-gradient(600px 300px at 10% -10%, rgba(96,165,250,.15), transparent),
                  radial-gradient(600px 300px at 90% -10%, rgba(52,211,153,.12), transparent);
      padding: 32px; border-radius: 20px; border: 1px solid var(--border);
    }
    .avatar { width: 160px; height: 160px; border-radius: 20px; object-fit: cover; border: 1px solid var(--border); }
    .name { margin: 0 0 4px; font-size: 34px; line-height: 1.2; letter-spacing: -0.02em; }
    .subtitle { margin: 6px 0 12px; color: var(--muted); }
    .links { display: flex; flex-wrap: wrap; gap: 10px; margin-top: 8px; }
    .pill { display: inline-flex; align-items: center; gap: 8px; padding: 6px 12px; border-radius: 999px; background: var(--chip); border: 1px solid var(--border); color: var(--text); font-weight: 500; }
    .cta { display: inline-block; padding: 10px 14px; border-radius: 10px; background: var(--accent); color: #0b1220; font-weight: 700; border: none; }

    .grid { display: grid; grid-template-columns: 1.1fr 1fr; gap: 24px; margin-top: 24px; }
    section.card { background: var(--card); border: 1px solid var(--border); border-radius: 16px; padding: 20px; }
    section.card h2 { margin: 0 0 10px; font-size: 22px; letter-spacing: -0.01em; }
    p { margin: 8px 0 12px; }

    .bullets { margin: 8px 0 0 0; padding-left: 18px; }
    .bullets li { margin: 6px 0; }

    /* Publications */
    .pub-controls { display: flex; flex-wrap: wrap; gap: 8px; margin-bottom: 14px; }
    .chip { padding: 6px 10px; border-radius: 999px; background: var(--chip); border: 1px solid var(--border); cursor: pointer; font-size: 13px; }
    .chip.active { outline: 2px solid var(--accent); }

    .pub-list { list-style: none; padding: 0; margin: 0; display: grid; gap: 14px; }
    .pub-item { background: #141826; border: 1px solid var(--border); border-radius: 14px; padding: 14px; }
    .pub-title { font-weight: 650; margin: 0 0 8px; }
    .authors strong { font-weight: 700; }
    .venue { color: var(--muted); font-size: 14px; }
    .tags { display: flex; flex-wrap: wrap; gap: 6px; margin-top: 8px; }
    .tag { background: #1a2032; border: 1px solid var(--border); padding: 4px 8px; font-size: 12px; border-radius: 999px; color: #c9d3ea; }

    .service ul { margin: 6px 0 0 0; padding-left: 18px; }

    footer { margin: 28px 0 12px; color: var(--muted); text-align: center; font-size: 14px; }

    @media (max-width: 880px) {
      header.hero { grid-template-columns: 1fr; text-align: center; }
      .links { justify-content: center; }
      .grid { grid-template-columns: 1fr; }
      .avatar { width: 180px; height: 180px; margin: 0 auto; }
    }
  </style>
</head>
<body>
  <div class="container">
    <header class="hero">
      <img class="avatar" src="selfie.jpg" alt="Portrait of Qiuhao Zeng" />
      <div>
        <h1 class="name">Qiuhao Zeng</h1>
        <div class="subtitle">PhD Candidate, Machine Learning Group ¬∑ University of Western Ontario</div>
        <div class="links">
          <a class="pill" href="mailto:qzeng53@uwo.ca">üìß qzeng53@uwo.ca</a>
          <a class="pill" href="https://www.linkedin.com/in/qiuhao-zeng-8a528184/" target="_blank" rel="noopener">in/LinkedIn</a>
          <a class="pill" href="https://scholar.google.ca/citations?user=MJdcPlgAAAAJ&hl=en" target="_blank" rel="noopener">üìö Google Scholar</a>
          <a class="pill" href="ZENG QIUHAO resume.pdf" target="_blank" rel="noopener">üìù CV (PDF)</a>
          <a class="cta" href="#publications">View Publications ‚Üì</a>
        </div>
      </div>
    </header>

    <div class="grid">
      <section class="card" id="about">
        <h2>About</h2>
        <p>
          I am a fourth‚Äëyear PhD candidate advised by Prof. Charles Ling (Fellow, Canadian Academy of Engineering) and Prof. Boyu Wang.
          My research spans efficient Transformer architectures and transfer learning under temporal distribution shifts. I‚Äôm currently open to
          <strong>post‚Äëdoctoral</strong> and <strong>research scientist</strong> opportunities.
        </p>
      </section>

      <section class="card" id="interests">
        <h2>Research Interests</h2>
        <ul class="bullets">
          <li>Efficient attention and Transformer acceleration (e.g., Triton‚Äëbased kernels, top‚Äëk attention).</li>
          <li>Transfer learning across evolving temporal domains; sequence modeling under distribution shift.</li>
          <li>Graph learning and domain adaptation.</li>
        </ul>
      </section>
    </div>

    <section class="card" id="publications">
      <h2>Publications</h2>
      <div class="pub-controls">
        <button class="chip active" data-filter="all">All</button>
        <button class="chip" data-filter="transformers">Transformers</button>
        <button class="chip" data-filter="sequential data">Temporal / Sequence</button>
        <button class="chip" data-filter="graph">Graph / DA</button>
        <button class="chip" data-filter="llm">LLMs </button>
        <button class="chip" data-filter="bci">BCI / EEG</button>
        <button class="chip" data-filter="journal">Journals</button>
      </div>
      <ul class="pub-list" id="pub-list">
        <!-- 2025 -->
        <li class="pub-item" data-tags="transformers">
          <div class="pub-title">ZETA: Leveraging Z‚Äëorder Curves for Efficient Top‚Äëk Attention</div>
          <div class="authors"><strong>Qiuhao Zeng</strong>, Jerry Huang, Peng Lu, Gezheng Xu, Boxing Chen, Charles Ling, Boyu Wang</div>
          <div class="venue">International Conference on Learning Representations (ICLR), 2025.</div>
          <div class="tags"><span class="tag">Transformers</span><span class="tag">Efficient Attention</span></div>
        </li>
        <li class="pub-item" data-tags="llm">
          <div class="pub-title">Calibrated Language Models and How to Find Them with Label Smoothing</div>
          <div class="authors">Jerry Huang, Peng Lu, <strong>Qiuhao Zeng</strong></div>
          <div class="venue">International Conference on Machine Learning (ICML), 2025.</div>
          <div class="tags"><span class="tag">LLMs</span><span class="tag">Calibration</span></div>
        </li>
        <li class="pub-item" data-tags="graph">
          <div class="pub-title">On the Benefits of Attribute‚ÄëDriven Graph Domain Adaptation</div>
          <div class="authors">Ruiyi Fang, Bingheng Li, Zhao Kang, <strong>Qiuhao Zeng</strong>, Nima Hosseini Dashtbayaz, Ruizhi Pu, Charles Ling, Boyu Wang</div>
          <div class="venue">International Conference on Learning Representations (ICLR), 2025.</div>
          <div class="tags"><span class="tag">Graph ML</span><span class="tag">Domain Adaptation</span></div>
        </li>
        <li class="pub-item" data-tags="graph">
          <div class="pub-title">Homophily Enhanced Graph Domain Adaptation</div>
          <div class="authors">Ruiyi Fang, Bingheng Li, Jingyu Zhao, Ruizhi Pu, <strong>Qiuhao Zeng</strong>, Gezheng Xu, Charles Ling, Boyu Wang</div>
          <div class="venue">International Conference on Machine Learning (ICML), 2025.</div>
          <div class="tags"><span class="tag">Graph ML</span><span class="tag">Homophily</span></div>
        </li>

        <!-- 2024 -->
        <li class="pub-item" data-tags="sequential data">
          <div class="pub-title">Towards Understanding Evolving Patterns in Sequential Data</div>
          <div class="authors"><strong>Qiuhao Zeng</strong>, Long‚ÄëKai Huang, Qi Chen, Charles Ling, Boyu Wang</div>
          <div class="venue">Conference on Neural Information Processing Systems (NeurIPS), 2024 (Spotlight; Top 2.1%).</div>
          <div class="tags"><span class="tag">Temporal</span><span class="tag">Sequence</span></div>
        </li>
        <li class="pub-item" data-tags="sequential data">
          <div class="pub-title">Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time</div>
          <div class="authors"><strong>Qiuhao Zeng</strong>, Changjian Shui, Long‚ÄëKai Huang, Peng Liu, Xi Chen, Charles Ling, Boyu Wang</div>
          <div class="venue">International Conference on Learning Representations (ICLR), 2024 (Oral; Top 1.2%).</div>
          <div class="tags"><span class="tag">Temporal</span><span class="tag">Distribution Shift</span></div>
        </li>
        <li class="pub-item" data-tags="sequential data">
          <div class="pub-title">Generalizing Across Temporal Domains with Koopman Operators</div>
          <div class="authors"><strong>Qiuhao Zeng</strong>, Wei Wang, Fan Zhou, Gezheng Xu, Ruizhi Pu, Changjian Shui, Christian Gagn√©, Shichun Yang, Charles Ling, Boyu Wang</div>
          <div class="venue">AAAI Conference on Artificial Intelligence (AAAI), 2024.</div>
          <div class="tags"><span class="tag">Domain Generalization</span><span class="tag">Koopman</span></div>
        </li>

        <!-- 2023 -->
        <li class="pub-item" data-tags="sequential data">
          <div class="pub-title">Foresee What You Will Learn: Data Augmentation for Domain Generalization in Non‚ÄëStationary Environments</div>
          <div class="authors"><strong>Qiuhao Zeng</strong>, Wei Wang, Fan Zhou, Charles Ling, Boyu Wang</div>
          <div class="venue">AAAI Conference on Artificial Intelligence (AAAI), 2023.</div>
          <div class="tags"><span class="tag">Domain Generalization</span><span class="tag">Data Augmentation</span></div>
        </li>
        <li class="pub-item" data-tags="journal">
          <div class="pub-title">Episodic Task‚ÄëAgnostic Contrastive Training for Multi‚ÄëTask Learning</div>
          <div class="authors">Fan Zhou, Yuyi Chen, Jun Wen, <strong>Qiuhao Zeng</strong>, Changjian Shui, Charles X. Ling, Shichun Yang, Boyu Wang</div>
          <div class="venue">Neural Networks, 2023.</div>
          <div class="tags"><span class="tag">Multi‚ÄëTask</span><span class="tag">Contrastive</span></div>
        </li>
        <li class="pub-item" data-tags="bci journal">
          <div class="pub-title">LGGNet: Learning from Local‚ÄëGlobal‚ÄëGraph Representations for Brain‚ÄëComputer Interface</div>
          <div class="authors">Yi Ding, Neethu Robinson, Chengxuan Tong, <strong>Qiuhao Zeng</strong>, Cuntai Guan</div>
          <div class="venue">IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2023.</div>
          <div class="tags"><span class="tag">BCI</span><span class="tag">GNN</span></div>
        </li>
      </ul>
    </section>

    <div class="grid">
      <section class="card service" id="service">
        <h2>Academic Service</h2>
        <ul>
          <li>Conference Reviewer: ICLR, NeurIPS (Top Reviewer), ICML, AISTATS.</li>
          <li>Journal Reviewer: TNNLS, TMLR.</li>
          <li>Teaching Assistant: CS3346 (AI), CS2210 (Data Structures), CS3357 (Networks).</li>
        </ul>
      </section>
      <section class="card" id="patent">
        <h2>Patent</h2>
        <p><strong>Mental Arousal Level Regulation System and Method</strong>, PCT Patent no. PCT/SG2022/050243 (2022).</p>
      </section>
    </div>

    <section class="card" id="contact">
      <h2>Contact</h2>
      <p>Email: <a href="mailto:zengqhyy@gmail.com">zengqhyy@gmail.com</a> ¬∑ <a href="mailto:qzeng53@uwo.ca">qzeng53@uwo.ca</a></p>
      <p>Also on <a href="https://www.linkedin.com/in/qiuhao-zeng-8a528184/" target="_blank" rel="noopener">LinkedIn</a> and <a href="https://scholar.google.ca/citations?user=MJdcPlgAAAAJ&hl=en" target="_blank" rel="noopener">Google Scholar</a>.</p>
    </section>

    <footer>
      ¬© <span id="year"></span> Qiuhao Zeng ¬∑ Last updated Aug 2025
    </footer>
  </div>

  <script>
    // Year
    document.getElementById('year').textContent = new Date().getFullYear();

    // Publication filtering
    const chips = Array.from(document.querySelectorAll('.chip'));
    const items = Array.from(document.querySelectorAll('.pub-item'));
    chips.forEach(chip => {
      chip.addEventListener('click', () => {
        chips.forEach(c => c.classList.remove('active'));
        chip.classList.add('active');
        const filter = chip.dataset.filter;
        items.forEach(li => {
          if (filter === 'all') { li.style.display = ''; return; }
          const tags = (li.dataset.tags || '').split(/\s+/);
          li.style.display = tags.includes(filter) ? '' : 'none';
        });
      });
    });
  </script>
</body>
</html>
